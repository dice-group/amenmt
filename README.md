# amenmt


Low-resource languages such as Amharic are under-researched for several reasons, such as data scarcity, computing resources, and fewer or no expert researchers in the area. We revisit and re-asses the current state of Amharic machine translation, arguing that not all information and data are available to reproduce the reported results. During our assessment, we notice important drawback such as data and models inconsistencies. In this paper, we alleviate this drawback by providing an open-source baseline model based on Transformers along with a public curated dataset for guiding Amharic-English Machine Translation future works. Our model outperforms the state-of-the-art approaches on Amharic-English.
